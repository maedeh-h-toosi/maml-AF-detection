{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "EvCVKkIfRAah"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import os\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from functools import partial\n",
        "from scipy.signal import savgol_filter\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from time import time\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from prettytable import PrettyTable as pt\n",
        "from sklearn.utils import shuffle\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D\n",
        "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from warnings import filterwarnings\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import KFold\n",
        "from keras import layers\n",
        "import argparse\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras import regularizers\n",
        "from keras.layers import Input, Dropout, Activation, BatchNormalization, Add\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from keras.layers import  GlobalAveragePooling1D,AveragePooling1D ,MaxPool1D,MaxPooling2D,ZeroPadding1D, LSTM, Bidirectional\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.layers import Flatten, Conv2D, MaxPool2D\n",
        "from numpy import unique\n",
        "#from colorama import Fore, Back, Style\n",
        "from prettytable import PrettyTable\n",
        "filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnW4sQMPxHuY",
        "outputId": "492499ce-5ecc-4bed-ee85-84aff161d532"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbvzvdivRAaj"
      },
      "outputs": [],
      "source": [
        "# train_dataset = pd.read_csv('/content/drive/MyDrive/new_physionet.csv')\n",
        "# test_dataset = pd.read_csv('/content/drive/MyDrive/new_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "y7L39OULZqBs"
      },
      "outputs": [],
      "source": [
        "train_dataset = pd.read_csv('C:/Users/tousi.KCRND/Downloads/MAML/new_physionet.csv')\n",
        "test_dataset = pd.read_csv('C:/Users/tousi.KCRND/Downloads/MAML/new_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EFryDrf-RAaj"
      },
      "outputs": [],
      "source": [
        "train_dataset['label'] = train_dataset['label'].replace([2,3],0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DmgHU7dGRAaj"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "\n",
        "train_data = train_dataset[:train_size]\n",
        "val_data = train_dataset[train_size:]\n",
        "\n",
        "X_train = train_dataset.drop(columns=['label']).values\n",
        "y_train = train_dataset['label'].values\n",
        "X_val = val_data.drop(columns=['label']).values\n",
        "y_val = val_data['label'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_1 = test_dataset[test_dataset['label'] == 1].sample(n=50)\n",
        "label_0 = test_dataset[test_dataset['label'] == 0].sample(n=50)\n",
        "selected_rows_1 = pd.concat([label_1, label_0])\n",
        "Meta_df_2 = shuffle(selected_rows_1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "Meta_df_1 = test_dataset.drop(index=selected_rows_1.index)\n",
        "Meta_df_1 = shuffle(Meta_df_1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_meta = Meta_df_1.drop(columns=['label']).values\n",
        "y_train_meta = Meta_df_1['label'].values\n",
        "X_test_meta = Meta_df_2.drop(columns=['label']).values\n",
        "y_test_meta = Meta_df_2['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAqJzcJYRAak"
      },
      "outputs": [],
      "source": [
        "# X_train =  train_dataset.drop(columns=['label'])\n",
        "# y_train =  train_dataset['label']\n",
        "\n",
        "# X_test =  test_dataset.drop(columns=['label'])\n",
        "# y_test =  test_dataset['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_foU0paORAak"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_train_meta = scaler.transform(X_train_meta)\n",
        "X_test_meta = scaler.transform(X_test_meta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Convolutional layers used by MAML model.\"\"\"\n",
        "## NOTE: You do not need to modify this block but you will need to use it.\n",
        "seed = 123\n",
        "import tensorflow as tf\n",
        "\n",
        "def conv_block_1d(inp, cweight, bweight, bn, activation=tf.nn.relu):\n",
        "    \"\"\" Perform conv, batch norm, and nonlinearity \"\"\"\n",
        "    conv_output = tf.nn.conv1d(input=inp, filters=cweight, stride=1, padding='SAME') + bweight\n",
        "    normed = bn(conv_output)\n",
        "    normed = activation(normed)\n",
        "    return normed\n",
        "\n",
        "class ConvLayers(tf.keras.layers.Layer):\n",
        "    def __init__(self, channels, dim_hidden, dim_output, signal_length):\n",
        "        super(ConvLayers, self).__init__()\n",
        "        self.channels = channels\n",
        "        self.dim_hidden = dim_hidden\n",
        "        self.dim_output = dim_output\n",
        "        self.signal_length = signal_length\n",
        "\n",
        "        weights = {}\n",
        "\n",
        "        dtype = tf.float32\n",
        "        weight_initializer = tf.keras.initializers.GlorotUniform()\n",
        "        k = 3\n",
        "\n",
        "        weights['conv1'] = tf.Variable(weight_initializer(shape=[k, self.channels, self.dim_hidden]), name='conv1', dtype=dtype)\n",
        "        weights['b1'] = tf.Variable(tf.zeros([self.dim_hidden]), name='b1')\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization(name='bn1')\n",
        "        weights['conv2'] = tf.Variable(weight_initializer(shape=[k, self.dim_hidden, self.dim_hidden]), name='conv2', dtype=dtype)\n",
        "        weights['b2'] = tf.Variable(tf.zeros([self.dim_hidden]), name='b2')\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization(name='bn2')\n",
        "        weights['conv3'] = tf.Variable(weight_initializer(shape=[k, self.dim_hidden, self.dim_hidden]), name='conv3', dtype=dtype)\n",
        "        weights['b3'] = tf.Variable(tf.zeros([self.dim_hidden]), name='b3')\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization(name='bn3')\n",
        "        weights['conv4'] = tf.Variable(weight_initializer(shape=[k, self.dim_hidden, self.dim_hidden]), name='conv4', dtype=dtype)\n",
        "        weights['b4'] = tf.Variable(tf.zeros([self.dim_hidden]), name='b4')\n",
        "        self.bn4 = tf.keras.layers.BatchNormalization(name='bn4')\n",
        "        weights['w5'] = tf.Variable(weight_initializer(shape=[self.dim_hidden, self.dim_output]), name='w5', dtype=dtype)\n",
        "        weights['b5'] = tf.Variable(tf.zeros([self.dim_output]), name='b5')\n",
        "        self.conv_weights = weights\n",
        "\n",
        "    def call(self, inp, weights):\n",
        "        channels = self.channels\n",
        "        inp = tf.reshape(inp, [-1, self.signal_length, channels])\n",
        "        hidden1 = conv_block_1d(inp, weights['conv1'], weights['b1'], self.bn1)\n",
        "        hidden2 = conv_block_1d(hidden1, weights['conv2'], weights['b2'], self.bn2)\n",
        "        hidden3 = conv_block_1d(hidden2, weights['conv3'], weights['b3'], self.bn3)\n",
        "        hidden4 = conv_block_1d(hidden3, weights['conv4'], weights['b4'], self.bn4)\n",
        "        hidden4 = tf.reduce_mean(hidden4, axis=1)\n",
        "        return tf.matmul(hidden4, weights['w5']) + weights['b5']\n",
        "\n",
        "# Example usage\n",
        "# channels = 1\n",
        "# dim_hidden = 64\n",
        "# dim_output = 4\n",
        "# signal_length = 1000\n",
        "\n",
        "# model = ConvLayers(channels, dim_hidden, dim_output, signal_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mobilenet =  MobileNetV2((1000,1,1), 4, 1.0)\n",
        "# trainable_variables = mobilenet.get_trainable_variables()\n",
        "# trainable_weights = mobilenet.get_trainable_weights()\n",
        "\n",
        "# print(\"Trainable variables:\", trainable_variables)\n",
        "# print(\"Trainable weights:\", trainable_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPs6NVKQWudB"
      },
      "outputs": [],
      "source": [
        "# def build_meta_model(input_shape):\n",
        "#     #inner_model = build_model(input_shape)\n",
        "#     inner_model =  MobileNetv2((X_train.shape[1],1), 1, 1.0)\n",
        "#     input_layer = layers.Input(shape=input_shape)\n",
        "#     inner_weights = inner_model(input_layer)\n",
        "#     meta_output = layers.Dense(1)(inner_weights)\n",
        "\n",
        "#     model = keras.Model(inputs=input_layer, outputs=meta_output)\n",
        "\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTyOU_g9L-M-"
      },
      "source": [
        "# DataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Y_OXHOjvLL58"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(object):\n",
        "    def __init__(self, X_train, y_train, num_classes, num_samples_per_class,\n",
        "                 X_val=None, y_val=None, X_train_meta=None, y_train_meta=None,\n",
        "                 X_test_meta=None, y_test_meta=None, num_meta_test_classes=None,\n",
        "                 num_meta_test_samples_per_class=None):\n",
        "        \n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        \n",
        "        self.X_train_meta = X_train_meta\n",
        "        self.y_train_meta = y_train_meta\n",
        "        self.X_test_meta = X_test_meta\n",
        "        self.y_test_meta = y_test_meta\n",
        "        \n",
        "        self.num_samples_per_class = num_samples_per_class\n",
        "        self.num_classes = num_classes\n",
        "        self.num_meta_test_samples_per_class = num_meta_test_samples_per_class\n",
        "        self.num_meta_test_classes = num_meta_test_classes\n",
        "        self.dim_input = X_train.shape[1] \n",
        "        self.dim_output = num_classes\n",
        "\n",
        "    def sample_batch(self, batch_type, batch_size, shuffle=True):\n",
        "        if batch_type == \"meta_train\":\n",
        "            X, y = self.X_train, self.y_train\n",
        "        elif batch_type == \"meta_val\":\n",
        "            X, y = self.X_val, self.y_val\n",
        "            \n",
        "        elif batch_type == \"meta_fine_tune\":\n",
        "            X, y = self.X_train_meta, self.y_train_meta\n",
        "        else:  # \"meta_test\"\n",
        "            X = self.X_test_meta\n",
        "            y = self.y_test_meta\n",
        "            num_classes = self.num_meta_test_classes\n",
        "            num_samples_per_class = self.num_meta_test_samples_per_class\n",
        "\n",
        "\n",
        "        all_signal_batches = []\n",
        "        all_label_batches = []\n",
        "        for _ in range(batch_size):\n",
        "            sampled_signals = []\n",
        "            sampled_labels = []\n",
        "            sampled_classes = np.random.choice(np.unique(y), self.num_classes, replace=True)\n",
        "            for class_label in sampled_classes:\n",
        "                class_indices = np.where(y == class_label)[0]\n",
        "                num_samples_available = len(class_indices)\n",
        "                num_samples_to_select = min(num_samples_available, self.num_samples_per_class)\n",
        "                selected_indices = np.random.choice(class_indices, num_samples_to_select, replace=False)\n",
        "                if isinstance(selected_indices, int):\n",
        "                    selected_indices = [selected_indices]  # Convert single integer to list\n",
        "                sampled_signals.extend(X[selected_indices])\n",
        "                sampled_labels.extend([class_label] * num_samples_to_select)  # Use num_samples_to_select instead of self.num_samples_per_class\n",
        "\n",
        "            # Convert to numpy arrays\n",
        "            sampled_signals = np.array(sampled_signals)\n",
        "            sampled_labels = np.array(sampled_labels)\n",
        "\n",
        "            # Shuffle within the batch if needed\n",
        "            if shuffle:\n",
        "                indices = np.arange(sampled_signals.shape[0])\n",
        "                np.random.shuffle(indices)\n",
        "                sampled_signals = sampled_signals[indices]\n",
        "                sampled_labels = sampled_labels[indices]\n",
        "\n",
        "            # One-hot encode labels\n",
        "            labels_one_hot = np.eye(self.num_classes)[sampled_labels]\n",
        "\n",
        "            all_signal_batches.append(sampled_signals)\n",
        "            all_label_batches.append(labels_one_hot)\n",
        "\n",
        "        all_signal_batches = np.stack(all_signal_batches)\n",
        "        all_label_batches = np.stack(all_label_batches)\n",
        "\n",
        "        return all_signal_batches, all_label_batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "4Tv_xgalZqBv"
      },
      "outputs": [],
      "source": [
        "# num_classes = 2\n",
        "# num_samples_per_class = 5\n",
        "# num_meta_test_classes = 2\n",
        "# num_meta_test_samples_per_class = 5\n",
        "\n",
        "# # Assuming you have defined X_train, y_train, X_val, y_val, X_train_meta, y_train_meta, X_test_meta, and y_test_meta\n",
        "# data_generator = DataGenerator(X_train, y_train, num_classes, num_samples_per_class,\n",
        "#                                X_val, y_val, X_train_meta, y_train_meta, X_test_meta,\n",
        "#                                y_test_meta, num_meta_test_classes, num_meta_test_samples_per_class)\n",
        "\n",
        "# batch_type = \"meta_test\"\n",
        "# batch_size = 25\n",
        "\n",
        "# # Generate a batch for meta-testing\n",
        "# signals_batch, labels_batch = data_generator.sample_batch(batch_type, batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KoEXumVLVWw"
      },
      "source": [
        "# MAML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6aFLwif7Agne"
      },
      "outputs": [],
      "source": [
        "# def cross_entropy_loss(pred, label, k_shot):\n",
        "#     pred_float = tf.cast(pred, tf.float32)\n",
        "#     label_float = tf.cast(label, tf.float32)\n",
        "#     return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred_float, labels=label_float)/k_shot)\n",
        "\n",
        "\n",
        "def cross_entropy_loss(pred, label, k_shot):\n",
        "    if not isinstance(pred, tf.Tensor):\n",
        "        raise TypeError(\"pred must be a tf.Tensor\")\n",
        "    if not isinstance(label, tf.Tensor):\n",
        "        raise TypeError(\"label must be a tf.Tensor\")\n",
        "    \n",
        "    # Check compatibility of shapes (optional)\n",
        "    if pred.shape != label.shape:\n",
        "        raise ValueError(\"Shape mismatch between pred and label\")\n",
        "\n",
        "    pred_float = tf.cast(pred, tf.float32)\n",
        "    label_float = tf.cast(label, tf.float32)\n",
        "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred_float, labels=label_float) / k_shot)\n",
        "\n",
        "def accuracy(labels, predictions):\n",
        "    if len(predictions.shape) > 1:\n",
        "        predictions = tf.argmax(predictions, axis=1)\n",
        "    if len(labels.shape) > 1:\n",
        "        labels = tf.argmax(labels, axis=1)\n",
        "\n",
        "    labels = tf.cast(labels, dtype=tf.float32)  # Cast labels to float32\n",
        "    predictions = tf.cast(predictions, dtype=tf.float32)\n",
        "\n",
        "    correct_predictions = tf.equal(labels, predictions)\n",
        "    return tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
        "\n",
        "# def accuracy(labels, predictions):\n",
        "#   return tf.reduce_mean(tf.cast(tf.equal(labels, predictions), dtype=tf.float32))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "LoWAhoqURAal"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class MAML(tf.keras.Model):\n",
        "    def __init__(self, dim_input=1000, dim_output=2,\n",
        "                 num_inner_updates=1,\n",
        "                 inner_update_lr=0.4, k_shot=5, learn_inner_update_lr=False):\n",
        "        super(MAML, self).__init__()\n",
        "        self.dim_input = dim_input\n",
        "        self.dim_output = dim_output\n",
        "        self.inner_update_lr = inner_update_lr\n",
        "        self.num_inner_updates = num_inner_updates\n",
        "        self.loss_func = partial(cross_entropy_loss, k_shot=k_shot)\n",
        "        self.dim_hidden = 32\n",
        "        self.channels = 1\n",
        "        #self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "        self.k_shot = k_shot\n",
        "        #self.feature_extractor =  MobileNetV2((1000,1,1), 4, 1.0)\n",
        "        self.conv_layers = ConvLayers(self.channels, self.dim_hidden, self.dim_output, self.dim_input)\n",
        "        self.learn_inner_update_lr = learn_inner_update_lr\n",
        "        if self.learn_inner_update_lr:\n",
        "          self.inner_update_lr_dict = {}\n",
        "          for key in self.conv_layers.conv_weights.keys():\n",
        "            self.inner_update_lr_dict[key] = [tf.Variable(self.inner_update_lr, name='inner_update_lr_%s_%d' % (key, j)) for j in range(num_inner_updates)]\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inp, meta_batch_size=20, num_inner_updates=1):\n",
        "\n",
        "      def task_inner_loop(inp, reuse=True, meta_batch_size=25, num_inner_updates=1):\n",
        "        input_tr, input_ts, label_tr, label_ts = inp\n",
        "        task_output_tr_pre, task_loss_tr_pre, task_accuracy_tr_pre = None, None, None\n",
        "        task_outputs_ts, task_losses_ts, task_accuracies_ts = [], [], []\n",
        "\n",
        "        #weights_optimized = self.feature_extractor.get_weights()\n",
        "        #weights_optimized = self.feature_extractor.model.get_weights()\n",
        "        #trainable_variables =self.feature_extractor.model.get_trainable_variables()\n",
        "        weights = self.conv_layers.conv_weights\n",
        "        #print('weights:',weights)\n",
        "        # weights_optimized = {}\n",
        "        # for layer in self.feature_extractor.model.layers:\n",
        "        #     for weight in layer.weights:\n",
        "        #          weights_optimized[weight.name] = weight\n",
        "\n",
        "        #weights_optimized = {weight: weight for weight in self.feature_extractor.model.weights}\n",
        "        weights_optimized = dict(zip(weights.keys(), [weights[key] for key in weights.keys()]))\n",
        "\n",
        "        with tf.GradientTape(persistent=True) as inner_tape:\n",
        "            for j in range(num_inner_updates):\n",
        "              input_tr_expanded = tf.expand_dims(input_tr, axis=0)\n",
        "              #logits_tr = self.feature_extractor.model(input_tr_expanded)\n",
        "              logits_tr = self.conv_layers(input_tr_expanded, weights_optimized)\n",
        "              label_tr = tf.reshape(label_tr, (1, -1)) \n",
        "              # print(\"logits_tr:\", logits_tr.shape)\n",
        "              # print(\"label_tr:\", label_tr.shape)\n",
        "\n",
        "\n",
        "              loss_tr_j = self.loss_func(logits_tr, label_tr)\n",
        "              #print('loss_tr_j',loss_tr_j)\n",
        "\n",
        "              if (task_output_tr_pre is None) and (task_loss_tr_pre is None) and (task_accuracy_tr_pre is None):\n",
        "                    task_output_tr_pre = logits_tr\n",
        "                    task_loss_tr_pre = loss_tr_j\n",
        "\n",
        "                    task_accuracy_tr_pre = accuracy(\n",
        "                        label_tr,\n",
        "                        tf.nn.softmax(task_output_tr_pre)\n",
        "                    )\n",
        "\n",
        "            #grads = inner_tape.gradient(loss_tr_j, weights_optimized.values())\n",
        "              grads = inner_tape.gradient(loss_tr_j, list(weights_optimized.values()))\n",
        "              #print('grads',grads)\n",
        "              grad_dict = dict(zip(weights_optimized.keys(), grads))\n",
        "            \n",
        "              \n",
        "              if self.learn_inner_update_lr:\n",
        "                  # update optimized weights using learnable learning rate\n",
        "                  weights_optimized = dict(zip(weights_optimized.keys(),\n",
        "                                            [weights_optimized[key] - self.inner_update_lr_dict[key][j] * grad_dict[key] for key in weights_optimized.keys()]))\n",
        "                  \n",
        "              else:\n",
        "                  # update optimized weights\n",
        "                  weights_optimized = dict(zip(weights_optimized.keys(),\n",
        "                                      [weights_optimized[key] - self.inner_update_lr * grad_dict[key] for key in weights_optimized.keys()]))\n",
        "\n",
        "            # compute logits for test data\n",
        "            #print('done')\n",
        "              input_ts_expanded = tf.expand_dims(input_ts, axis=0)\n",
        "              #logits_ts = self.feature_extractor.model(input_ts_expanded)\n",
        "              logits_ts = self.conv_layers(input_ts_expanded, weights_optimized)\n",
        "\n",
        "            # compute loss\n",
        "              #label_ts_expanded = tf.squeeze(label_ts, axis=0)\n",
        "              label_ts = tf.reshape(label_ts, (1, -1)) \n",
        "              loss_ts_j = self.loss_func(label_ts, logits_ts)\n",
        "            # add to the task output list\n",
        "              task_outputs_ts.append(logits_ts)\n",
        "            # compute task loss on test data\n",
        "              task_losses_ts.append(loss_ts_j)\n",
        "\n",
        "      # compute accuracies after inner update step\n",
        "        for j in range(num_inner_updates):\n",
        "          predictions_ts = tf.nn.softmax(task_outputs_ts[j], axis=1)\n",
        "          task_accuracy_ts = accuracy(label_ts, predictions_ts)\n",
        "\n",
        "          task_accuracies_ts.append(task_accuracy_ts)\n",
        "\n",
        "        # print(\"task_output_tr_pre:\", task_output_tr_pre)\n",
        "        # print(\"task_loss_tr_pre:\", task_loss_tr_pre)\n",
        "        # print(\"task_accuracy_tr_pre:\", task_accuracy_tr_pre)\n",
        "        task_output = [task_output_tr_pre, task_outputs_ts, task_loss_tr_pre, task_losses_ts, task_accuracy_tr_pre,\n",
        "                      task_accuracies_ts]\n",
        "        return task_output\n",
        "\n",
        "\n",
        "      # def task_inner_loop_partial(inp_sample, meta_batch_size=25, num_inner_updates=1):\n",
        "      #     return task_inner_loop(\n",
        "      #         (inp_sample[0], inp_sample[1], inp_sample[2], inp_sample[3]),\n",
        "      #         False,\n",
        "      #         meta_batch_size,\n",
        "      #         num_inner_updates\n",
        "      #     )\n",
        "\n",
        "      input_tr, input_ts, label_tr, label_ts = inp\n",
        "\n",
        "      dummy_result = task_inner_loop((tf.identity(input_tr[0]),\n",
        "                                        tf.identity(input_ts[0]),\n",
        "                                        tf.identity(label_tr[0]),\n",
        "                                        tf.identity(label_ts[0])),\n",
        "                              False,\n",
        "                              meta_batch_size,\n",
        "                              num_inner_updates)\n",
        "      \n",
        "      \n",
        "    #   output_signature = (tf.float32, [tf.float32] * num_inner_updates, tf.float32, [tf.float32] * num_inner_updates,\n",
        "    #                 tf.float32, [tf.float32] * num_inner_updates)\n",
        "      out_dtype = [tf.float32, [tf.float32]*num_inner_updates, tf.float32, [tf.float32]*num_inner_updates]\n",
        "      out_dtype.extend([tf.float32, [tf.float32]*num_inner_updates])\n",
        "      task_inner_loop_partial = partial(task_inner_loop, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n",
        "      result = tf.map_fn(task_inner_loop_partial,\n",
        "                      elems=(input_tr, input_ts, label_tr, label_ts),\n",
        "                      dtype=out_dtype,\n",
        "                      parallel_iterations=meta_batch_size)\n",
        "      return result\n",
        "      \n",
        "#     result = tf.map_fn(task_inner_loop_partial,\n",
        "#                 elems=(input_tr, input_ts, label_tr, label_ts),\n",
        "#                 fn_output_signature=output_signature,\n",
        "#                 parallel_iterations=meta_batch_size)\n",
        "# return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH-QU3uAztCE"
      },
      "source": [
        "# outer loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "xy1pz_ousUsz"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import random\n",
        "\n",
        "\n",
        "def outer_train_step(inp, model, optim, meta_batch_size=25, num_inner_updates=1):\n",
        "  with tf.GradientTape(persistent=False) as outer_tape:\n",
        "    result = model(inp, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n",
        "\n",
        "    outputs_tr, outputs_ts, losses_tr_pre, losses_ts, accuracies_tr_pre, accuracies_ts = result\n",
        "\n",
        "    total_losses_ts = [tf.reduce_mean(loss_ts) for loss_ts in losses_ts]\n",
        "\n",
        "  gradients = outer_tape.gradient(total_losses_ts[-1], model.trainable_variables)\n",
        " # print('gradients',gradients)\n",
        "  optim.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  total_loss_tr_pre = tf.reduce_mean(losses_tr_pre)\n",
        "  total_accuracy_tr_pre = tf.reduce_mean(accuracies_tr_pre)\n",
        "  total_accuracies_ts = [tf.reduce_mean(accuracy_ts) for accuracy_ts in accuracies_ts]\n",
        "\n",
        "  return outputs_tr, outputs_ts, total_loss_tr_pre, total_losses_ts, total_accuracy_tr_pre, total_accuracies_ts\n",
        "\n",
        "def outer_eval_step(inp, model, meta_batch_size=25, num_inner_updates=1):\n",
        "  result = model(inp, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n",
        "\n",
        "  outputs_tr, outputs_ts, losses_tr_pre, losses_ts, accuracies_tr_pre, accuracies_ts = result\n",
        "\n",
        "  total_loss_tr_pre = tf.reduce_mean(losses_tr_pre)\n",
        "  total_losses_ts = [tf.reduce_mean(loss_ts) for loss_ts in losses_ts]\n",
        "\n",
        "  total_accuracy_tr_pre = tf.reduce_mean(accuracies_tr_pre)\n",
        "  total_accuracies_ts = [tf.reduce_mean(accuracy_ts) for accuracy_ts in accuracies_ts]\n",
        "\n",
        "  return outputs_tr, outputs_ts, total_loss_tr_pre, total_losses_ts, total_accuracy_tr_pre, total_accuracies_ts\n",
        "\n",
        "\n",
        "def meta_train_fn(model, data_generator,\n",
        "               n_way=2, meta_train_iterations=200, meta_batch_size=25,\n",
        "               k_shot=5, num_inner_updates=1, meta_lr=0.001):\n",
        "\n",
        "  SUMMARY_INTERVAL = 10\n",
        "  SAVE_INTERVAL = 100\n",
        "  PRINT_INTERVAL = SUMMARY_INTERVAL\n",
        "  TEST_PRINT_INTERVAL = SUMMARY_INTERVAL\n",
        "  LOG_CSV_INTERVAL = SUMMARY_INTERVAL\n",
        "\n",
        "  path = 'C:/Users/tousi.KCRND/Downloads/MAML/weights/'\n",
        "\n",
        "  pre_accuracies, post_accuracies = [], []\n",
        "\n",
        "  num_classes = 2\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=meta_lr)\n",
        "\n",
        "  task_train_acc_pre_optim, task_train_acc_post_optim, task_test_acc_pre_optim, task_test_acc_post_optim = 0., 0., 0., 0.\n",
        "\n",
        "  for itr in range(meta_train_iterations):\n",
        "\n",
        "    input_, label_ = data_generator.sample_batch(batch_type='meta_train', batch_size=meta_batch_size, shuffle=True)\n",
        "    #print('input shape:',input_.shape)\n",
        "\n",
        "    input_tr = np.reshape(input_[:, :n_way*k_shot, :], newshape=(-1, np.prod(data_generator.dim_input)))\n",
        "    input_ts = np.reshape(input_[:, n_way*k_shot:, :], newshape=(-1, np.prod(data_generator.dim_input)))\n",
        "    label_tr = np.reshape(label_[:, :n_way*k_shot, :], newshape=(-1, data_generator.dim_output))\n",
        "    label_ts = np.reshape(label_[:, n_way*k_shot:, :], newshape=(-1, data_generator.dim_output))\n",
        "\n",
        "    input_tr = np.reshape(input_tr, newshape=(-1, 1000, 1, 1))  \n",
        "    input_ts = np.reshape(input_ts, newshape=(-1, 1000, 1, 1))\n",
        "\n",
        "    # print('input_tr:',input_tr.shape)\n",
        "    # print('input_ts:',input_ts.shape)\n",
        "    # print('label tr:', label_tr.shape)\n",
        "    # print('label_ts:',label_ts.shape)\n",
        "\n",
        "\n",
        "\n",
        "    inp = (input_tr, input_ts, label_tr, label_ts)\n",
        "\n",
        "    result = outer_train_step(inp, model, optimizer, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n",
        "\n",
        "    if itr % SUMMARY_INTERVAL == 0:\n",
        "      pre_accuracies.append(result[-2])\n",
        "      post_accuracies.append(result[-1][-1])\n",
        "\n",
        "    if (itr!=0) and itr % PRINT_INTERVAL == 0:\n",
        "      task_train_acc_pre_optim = np.mean(pre_accuracies)\n",
        "      task_train_acc_post_optim = np.mean(post_accuracies)\n",
        "      print_str = 'Iteration %d: pre-inner-loop train accuracy: %.5f, post-inner-loop test accuracy: %.5f' % (itr, np.mean(pre_accuracies), np.mean(post_accuracies))\n",
        "      print(print_str)\n",
        "      pre_accuracies, post_accuracies = [], []\n",
        "\n",
        "    if (itr!=0) and itr % TEST_PRINT_INTERVAL == 0:\n",
        "\n",
        "      input_, label_ = data_generator.sample_batch(batch_type='meta_val', batch_size=meta_batch_size, shuffle=True)\n",
        "      input_tr = np.reshape(input_[:, :n_way*k_shot, :], newshape=(-1, np.prod(data_generator.dim_input)))\n",
        "      input_ts = np.reshape(input_[:, n_way*k_shot:, :], newshape=(-1, np.prod(data_generator.dim_input)))\n",
        "      label_tr = np.reshape(label_[:, :n_way*k_shot, :], newshape=(-1, data_generator.dim_output))\n",
        "      label_ts = np.reshape(label_[:, n_way*k_shot:, :], newshape=(-1, data_generator.dim_output))\n",
        "      input_tr = np.reshape(input_tr, newshape=(-1, 1000, 1, 1))  \n",
        "      input_ts = np.reshape(input_ts, newshape=(-1, 1000, 1, 1))\n",
        "\n",
        "\n",
        "      inp = (input_tr, input_ts, label_tr, label_ts)\n",
        "      result = outer_eval_step(inp, model, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n",
        "\n",
        "      task_test_acc_pre_optim = result[-2].numpy()\n",
        "      task_test_acc_post_optim = result[-1][-1].numpy()\n",
        "      print('Meta-validation pre-inner-loop train accuracy: %.5f, meta-validation post-inner-loop test accuracy: %.5f' % (result[-2], result[-1][-1]))\n",
        "\n",
        "    if (itr != 0) and itr % SAVE_INTERVAL == 0:\n",
        "        model_file = os.path.join(path, f'{itr}_model.h5')\n",
        "        print(\"Saving to \", model_file)\n",
        "        model.save_weights(model_file)\n",
        "\n",
        "\n",
        "NUM_META_TEST_POINTS = 100\n",
        "\n",
        "def meta_test_fn(model, data_generator, n_way=2, meta_batch_size=25, k_shot=5,\n",
        "              num_inner_updates=1):\n",
        "\n",
        "  #num_classes = data_generator.num_classes\n",
        "  path = 'C:/Users/tousi.KCRND/Downloads/MAML/weights/'\n",
        "\n",
        "  num_classes = 2\n",
        "\n",
        "  np.random.seed(1)\n",
        "  random.seed(1)\n",
        "\n",
        "  meta_test_accuracies = []\n",
        "\n",
        "  for _ in range(NUM_META_TEST_POINTS):\n",
        "\n",
        "    input_, label_ = data_generator.sample_batch(batch_type='meta_test', batch_size=meta_batch_size, shuffle=True)\n",
        "    input_tr = np.reshape(input_[:, :n_way*k_shot, :], newshape=(-1, np.prod(data_generator.dim_input)))\n",
        "    input_ts = np.reshape(input_[:, n_way*k_shot:, :], newshape=(-1, np.prod(data_generator.dim_input)))\n",
        "    label_tr = np.reshape(label_[:, :n_way*k_shot, :], newshape=(-1, data_generator.dim_output))\n",
        "    label_ts = np.reshape(label_[:, n_way*k_shot:, :], newshape=(-1, data_generator.dim_output))\n",
        "\n",
        "    input_tr = np.reshape(input_tr, newshape=(-1, 1000, 1, 1))  \n",
        "    input_ts = np.reshape(input_ts, newshape=(-1, 1000, 1, 1))\n",
        "\n",
        "\n",
        "    inp = (input_tr, input_ts, label_tr, label_ts)\n",
        "    result = outer_eval_step(inp, model, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n",
        "\n",
        "    meta_test_accuracies.append(result[-1][-1])\n",
        "\n",
        "  meta_test_accuracies = np.array(meta_test_accuracies)\n",
        "  means = np.mean(meta_test_accuracies)\n",
        "  stds = np.std(meta_test_accuracies)\n",
        "  ci95 = 1.96*stds/np.sqrt(NUM_META_TEST_POINTS)\n",
        "\n",
        "  print('Mean meta-test accuracy/loss, stddev, and confidence intervals')\n",
        "  print((means, stds, ci95))\n",
        "\n",
        "\n",
        "def run_maml(n_way, k_shot, meta_batch_size=25, meta_lr=0.001,\n",
        "             inner_update_lr=0.4, num_inner_updates=1,\n",
        "             learn_inner_update_lr=False,\n",
        "             resume=False, resume_itr=0,\n",
        "             meta_train=True,\n",
        "             meta_train_iterations=1000, meta_train_k_shot=-1,\n",
        "             meta_train_inner_update_lr=-1):\n",
        "\n",
        "  # call data_generator and get data with k_shot*2 samples per class\n",
        "\n",
        "  path = 'C:/Users/tousi.KCRND/Downloads/MAML/weights/'\n",
        "  data_generator = DataGenerator(X_train, y_train, n_way, k_shot*2,\n",
        "                               X_val, y_val, X_train_meta, y_train_meta, X_test_meta,\n",
        "                               y_test_meta, n_way, k_shot*2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # set up MAML model\n",
        "  dim_output = data_generator.dim_output\n",
        "  dim_input = data_generator.dim_input\n",
        "  #print('1')\n",
        "  model = MAML(dim_input,\n",
        "              dim_output,\n",
        "              num_inner_updates=num_inner_updates,\n",
        "              inner_update_lr=inner_update_lr,\n",
        "              k_shot=k_shot,\n",
        "              learn_inner_update_lr=learn_inner_update_lr)\n",
        "  #print('2')\n",
        "  if meta_train_k_shot == -1:\n",
        "    meta_train_k_shot = k_shot\n",
        "  if meta_train_inner_update_lr == -1:\n",
        "    meta_train_inner_update_lr = inner_update_lr\n",
        "\n",
        "  # exp_string = 'cls_'+str(n_way)+'.mbs_'+str(meta_batch_size) + '.k_shot_' + str(meta_train_k_shot) + '.inner_numstep_' + str(num_inner_updates) + '.inner_updatelr_' + str(meta_train_inner_update_lr) + '.learn_inner_update_lr_' + str(learn_inner_update_lr)\n",
        "  # logfile = exp_string+'.csv'\n",
        "\n",
        "  if meta_train:\n",
        "    meta_train_fn(model, data_generator,\n",
        "                  n_way, meta_train_iterations, meta_batch_size, k_shot,\n",
        "                  num_inner_updates, meta_lr)\n",
        "  else:\n",
        "    meta_batch_size = 1\n",
        "    modeldir = 'C:/Users/tousi.KCRND/Downloads/MAML/weights'\n",
        "    exp_string = '900_model.h5'\n",
        "    model_file = os.path.join(modeldir, exp_string)\n",
        "\n",
        "    if os.path.exists(model_file):\n",
        "        # Load weights\n",
        "        # model.load_weights(model_file)\n",
        "        # print(\"Model weights loaded successfully from\", model_file)\n",
        "        meta_test_fn(model, data_generator, n_way, meta_batch_size, k_shot, num_inner_updates)\n",
        "    else:\n",
        "      print(\"Model file not found at\", model_file)\n",
        "\n",
        "\n",
        "    #model_file = tf.train.latest_checkpoint(modeldir + '/' + exp_string)\n",
        "    # print(\"Restoring model weights from \", model_file)\n",
        "    # model.load_weights(model_file)\n",
        "\n",
        "  # path = 'C:/Users/tousi.KCRND/Downloads/MAML/weights/'\n",
        "  # latest_checkpoint = tf.train.latest_checkpoint(path)\n",
        "  # if latest_checkpoint:\n",
        "  #     print(\"Restoring model weights from \", latest_checkpoint)\n",
        "  #     model.load_weights(latest_checkpoint)\n",
        "  # else:\n",
        "  #     print(\"No checkpoint found in \", path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUBIxZ4nLYv1"
      },
      "source": [
        "# RUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JHDiHMxgZqBx",
        "outputId": "fee7e166-11b0-464d-df76-7fb13b64a7f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:From c:\\Users\\tousi.KCRND\\AppData\\Local\\miniconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "Iteration 10: pre-inner-loop train accuracy: 0.58800, post-inner-loop test accuracy: 0.81600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.48000, meta-validation post-inner-loop test accuracy: 0.68000\n",
            "Iteration 20: pre-inner-loop train accuracy: 0.54400, post-inner-loop test accuracy: 0.73600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.47600, meta-validation post-inner-loop test accuracy: 0.74400\n",
            "Iteration 30: pre-inner-loop train accuracy: 0.57200, post-inner-loop test accuracy: 0.76800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.42400, meta-validation post-inner-loop test accuracy: 0.80000\n",
            "Iteration 40: pre-inner-loop train accuracy: 0.40400, post-inner-loop test accuracy: 0.77600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.51200, meta-validation post-inner-loop test accuracy: 0.66400\n",
            "Iteration 50: pre-inner-loop train accuracy: 0.49200, post-inner-loop test accuracy: 0.78400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.44000, meta-validation post-inner-loop test accuracy: 0.76000\n",
            "Iteration 60: pre-inner-loop train accuracy: 0.58000, post-inner-loop test accuracy: 0.69600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.58000, meta-validation post-inner-loop test accuracy: 0.81600\n",
            "Iteration 70: pre-inner-loop train accuracy: 0.46400, post-inner-loop test accuracy: 0.74400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.60000, meta-validation post-inner-loop test accuracy: 0.87200\n",
            "Iteration 80: pre-inner-loop train accuracy: 0.42000, post-inner-loop test accuracy: 0.64800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.56400, meta-validation post-inner-loop test accuracy: 0.80000\n",
            "Iteration 90: pre-inner-loop train accuracy: 0.52000, post-inner-loop test accuracy: 0.78400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.46400, meta-validation post-inner-loop test accuracy: 0.82400\n",
            "Iteration 100: pre-inner-loop train accuracy: 0.43200, post-inner-loop test accuracy: 0.67200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.42400, meta-validation post-inner-loop test accuracy: 0.72000\n",
            "Saving to  C:/Users/tousi.KCRND/Downloads/MAML/weights/100_model.h5\n",
            "Iteration 110: pre-inner-loop train accuracy: 0.43600, post-inner-loop test accuracy: 0.72800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.47200, meta-validation post-inner-loop test accuracy: 0.73600\n",
            "Iteration 120: pre-inner-loop train accuracy: 0.59600, post-inner-loop test accuracy: 0.86400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.41600, meta-validation post-inner-loop test accuracy: 0.80800\n",
            "Iteration 130: pre-inner-loop train accuracy: 0.47200, post-inner-loop test accuracy: 0.67200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.36800, meta-validation post-inner-loop test accuracy: 0.69600\n",
            "Iteration 140: pre-inner-loop train accuracy: 0.52800, post-inner-loop test accuracy: 0.60800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.51200, meta-validation post-inner-loop test accuracy: 0.67200\n",
            "Iteration 150: pre-inner-loop train accuracy: 0.64800, post-inner-loop test accuracy: 0.76800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.51200, meta-validation post-inner-loop test accuracy: 0.66400\n",
            "Iteration 160: pre-inner-loop train accuracy: 0.55200, post-inner-loop test accuracy: 0.81600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.42400, meta-validation post-inner-loop test accuracy: 0.79200\n",
            "Iteration 170: pre-inner-loop train accuracy: 0.46400, post-inner-loop test accuracy: 0.66400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.58800, meta-validation post-inner-loop test accuracy: 0.77600\n",
            "Iteration 180: pre-inner-loop train accuracy: 0.43200, post-inner-loop test accuracy: 0.72800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.54000, meta-validation post-inner-loop test accuracy: 0.77600\n",
            "Iteration 190: pre-inner-loop train accuracy: 0.52400, post-inner-loop test accuracy: 0.78400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.56800, meta-validation post-inner-loop test accuracy: 0.73600\n",
            "Iteration 200: pre-inner-loop train accuracy: 0.34800, post-inner-loop test accuracy: 0.76800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.51600, meta-validation post-inner-loop test accuracy: 0.72000\n",
            "Saving to  C:/Users/tousi.KCRND/Downloads/MAML/weights/200_model.h5\n",
            "Iteration 210: pre-inner-loop train accuracy: 0.48800, post-inner-loop test accuracy: 0.76000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.40000, meta-validation post-inner-loop test accuracy: 0.69600\n",
            "Iteration 220: pre-inner-loop train accuracy: 0.53200, post-inner-loop test accuracy: 0.61600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52400, meta-validation post-inner-loop test accuracy: 0.76800\n",
            "Iteration 230: pre-inner-loop train accuracy: 0.45200, post-inner-loop test accuracy: 0.60800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.54000, meta-validation post-inner-loop test accuracy: 0.67200\n",
            "Iteration 240: pre-inner-loop train accuracy: 0.54000, post-inner-loop test accuracy: 0.60000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.46800, meta-validation post-inner-loop test accuracy: 0.66400\n",
            "Iteration 250: pre-inner-loop train accuracy: 0.44800, post-inner-loop test accuracy: 0.61600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.56000, meta-validation post-inner-loop test accuracy: 0.64800\n",
            "Iteration 260: pre-inner-loop train accuracy: 0.44000, post-inner-loop test accuracy: 0.68000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.49200, meta-validation post-inner-loop test accuracy: 0.72800\n",
            "Iteration 270: pre-inner-loop train accuracy: 0.46000, post-inner-loop test accuracy: 0.84000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52800, meta-validation post-inner-loop test accuracy: 0.81600\n",
            "Iteration 280: pre-inner-loop train accuracy: 0.56400, post-inner-loop test accuracy: 0.74400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52800, meta-validation post-inner-loop test accuracy: 0.80000\n",
            "Iteration 290: pre-inner-loop train accuracy: 0.46000, post-inner-loop test accuracy: 0.74400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.55200, meta-validation post-inner-loop test accuracy: 0.77600\n",
            "Iteration 300: pre-inner-loop train accuracy: 0.52000, post-inner-loop test accuracy: 0.71200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.51600, meta-validation post-inner-loop test accuracy: 0.70400\n",
            "Saving to  C:/Users/tousi.KCRND/Downloads/MAML/weights/300_model.h5\n",
            "Iteration 310: pre-inner-loop train accuracy: 0.52800, post-inner-loop test accuracy: 0.65600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.41600, meta-validation post-inner-loop test accuracy: 0.72800\n",
            "Iteration 320: pre-inner-loop train accuracy: 0.49600, post-inner-loop test accuracy: 0.60000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.49600, meta-validation post-inner-loop test accuracy: 0.74400\n",
            "Iteration 330: pre-inner-loop train accuracy: 0.45600, post-inner-loop test accuracy: 0.70400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.42000, meta-validation post-inner-loop test accuracy: 0.82400\n",
            "Iteration 340: pre-inner-loop train accuracy: 0.40400, post-inner-loop test accuracy: 0.69600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.56800, meta-validation post-inner-loop test accuracy: 0.66400\n",
            "Iteration 350: pre-inner-loop train accuracy: 0.51600, post-inner-loop test accuracy: 0.72800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.48000, meta-validation post-inner-loop test accuracy: 0.74400\n",
            "Iteration 360: pre-inner-loop train accuracy: 0.66800, post-inner-loop test accuracy: 0.67200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.41600, meta-validation post-inner-loop test accuracy: 0.70400\n",
            "Iteration 370: pre-inner-loop train accuracy: 0.42400, post-inner-loop test accuracy: 0.67200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.45200, meta-validation post-inner-loop test accuracy: 0.80000\n",
            "Iteration 380: pre-inner-loop train accuracy: 0.47600, post-inner-loop test accuracy: 0.67200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.45200, meta-validation post-inner-loop test accuracy: 0.77600\n",
            "Iteration 390: pre-inner-loop train accuracy: 0.56800, post-inner-loop test accuracy: 0.76800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.58400, meta-validation post-inner-loop test accuracy: 0.67200\n",
            "Iteration 400: pre-inner-loop train accuracy: 0.52000, post-inner-loop test accuracy: 0.77600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.40800, meta-validation post-inner-loop test accuracy: 0.72000\n",
            "Saving to  C:/Users/tousi.KCRND/Downloads/MAML/weights/400_model.h5\n",
            "Iteration 410: pre-inner-loop train accuracy: 0.44000, post-inner-loop test accuracy: 0.81600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.58800, meta-validation post-inner-loop test accuracy: 0.75200\n",
            "Iteration 420: pre-inner-loop train accuracy: 0.53600, post-inner-loop test accuracy: 0.60000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.48400, meta-validation post-inner-loop test accuracy: 0.76800\n",
            "Iteration 430: pre-inner-loop train accuracy: 0.50400, post-inner-loop test accuracy: 0.76000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.51600, meta-validation post-inner-loop test accuracy: 0.73600\n",
            "Iteration 440: pre-inner-loop train accuracy: 0.46400, post-inner-loop test accuracy: 0.69600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.51200, meta-validation post-inner-loop test accuracy: 0.75200\n",
            "Iteration 450: pre-inner-loop train accuracy: 0.60000, post-inner-loop test accuracy: 0.73600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.41200, meta-validation post-inner-loop test accuracy: 0.77600\n",
            "Iteration 460: pre-inner-loop train accuracy: 0.42800, post-inner-loop test accuracy: 0.76800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.45200, meta-validation post-inner-loop test accuracy: 0.68800\n",
            "Iteration 470: pre-inner-loop train accuracy: 0.58000, post-inner-loop test accuracy: 0.71200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.42000, meta-validation post-inner-loop test accuracy: 0.70400\n",
            "Iteration 480: pre-inner-loop train accuracy: 0.41600, post-inner-loop test accuracy: 0.79200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52000, meta-validation post-inner-loop test accuracy: 0.70400\n",
            "Iteration 490: pre-inner-loop train accuracy: 0.53600, post-inner-loop test accuracy: 0.70400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.47200, meta-validation post-inner-loop test accuracy: 0.68000\n",
            "Iteration 500: pre-inner-loop train accuracy: 0.46400, post-inner-loop test accuracy: 0.67200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52800, meta-validation post-inner-loop test accuracy: 0.81600\n",
            "Saving to  C:/Users/tousi.KCRND/Downloads/MAML/weights/500_model.h5\n",
            "Iteration 510: pre-inner-loop train accuracy: 0.55600, post-inner-loop test accuracy: 0.73600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.43600, meta-validation post-inner-loop test accuracy: 0.72000\n",
            "Iteration 520: pre-inner-loop train accuracy: 0.68800, post-inner-loop test accuracy: 0.84800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.50400, meta-validation post-inner-loop test accuracy: 0.84800\n",
            "Iteration 530: pre-inner-loop train accuracy: 0.53600, post-inner-loop test accuracy: 0.76800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.46800, meta-validation post-inner-loop test accuracy: 0.68800\n",
            "Iteration 540: pre-inner-loop train accuracy: 0.55600, post-inner-loop test accuracy: 0.72800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.49600, meta-validation post-inner-loop test accuracy: 0.80000\n",
            "Iteration 550: pre-inner-loop train accuracy: 0.53200, post-inner-loop test accuracy: 0.56000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.62800, meta-validation post-inner-loop test accuracy: 0.76800\n",
            "Iteration 560: pre-inner-loop train accuracy: 0.52000, post-inner-loop test accuracy: 0.74400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.44400, meta-validation post-inner-loop test accuracy: 0.80000\n",
            "Iteration 570: pre-inner-loop train accuracy: 0.48400, post-inner-loop test accuracy: 0.70400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52000, meta-validation post-inner-loop test accuracy: 0.64000\n",
            "Iteration 580: pre-inner-loop train accuracy: 0.51600, post-inner-loop test accuracy: 0.79200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.38400, meta-validation post-inner-loop test accuracy: 0.76000\n",
            "Iteration 590: pre-inner-loop train accuracy: 0.47600, post-inner-loop test accuracy: 0.72800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.40400, meta-validation post-inner-loop test accuracy: 0.76000\n",
            "Iteration 600: pre-inner-loop train accuracy: 0.54400, post-inner-loop test accuracy: 0.72800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.42000, meta-validation post-inner-loop test accuracy: 0.75200\n",
            "Saving to  C:/Users/tousi.KCRND/Downloads/MAML/weights/600_model.h5\n",
            "Iteration 610: pre-inner-loop train accuracy: 0.57200, post-inner-loop test accuracy: 0.67200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.54400, meta-validation post-inner-loop test accuracy: 0.72000\n",
            "Iteration 620: pre-inner-loop train accuracy: 0.54400, post-inner-loop test accuracy: 0.60800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.53200, meta-validation post-inner-loop test accuracy: 0.77600\n",
            "Iteration 630: pre-inner-loop train accuracy: 0.44000, post-inner-loop test accuracy: 0.66400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.49600, meta-validation post-inner-loop test accuracy: 0.76800\n",
            "Iteration 640: pre-inner-loop train accuracy: 0.60000, post-inner-loop test accuracy: 0.86400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.49200, meta-validation post-inner-loop test accuracy: 0.80800\n",
            "Iteration 650: pre-inner-loop train accuracy: 0.49200, post-inner-loop test accuracy: 0.71200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.43200, meta-validation post-inner-loop test accuracy: 0.68800\n",
            "Iteration 660: pre-inner-loop train accuracy: 0.65600, post-inner-loop test accuracy: 0.78400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.46000, meta-validation post-inner-loop test accuracy: 0.78400\n",
            "Iteration 670: pre-inner-loop train accuracy: 0.58800, post-inner-loop test accuracy: 0.71200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.49200, meta-validation post-inner-loop test accuracy: 0.68800\n",
            "Iteration 680: pre-inner-loop train accuracy: 0.54000, post-inner-loop test accuracy: 0.69600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.46000, meta-validation post-inner-loop test accuracy: 0.72800\n",
            "Iteration 690: pre-inner-loop train accuracy: 0.51600, post-inner-loop test accuracy: 0.74400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.42000, meta-validation post-inner-loop test accuracy: 0.65600\n",
            "Iteration 700: pre-inner-loop train accuracy: 0.51600, post-inner-loop test accuracy: 0.78400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.60800, meta-validation post-inner-loop test accuracy: 0.75200\n",
            "Saving to  C:/Users/tousi.KCRND/Downloads/MAML/weights/700_model.h5\n",
            "Iteration 710: pre-inner-loop train accuracy: 0.54000, post-inner-loop test accuracy: 0.76800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.45600, meta-validation post-inner-loop test accuracy: 0.68800\n",
            "Iteration 720: pre-inner-loop train accuracy: 0.52400, post-inner-loop test accuracy: 0.75200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52000, meta-validation post-inner-loop test accuracy: 0.70400\n",
            "Iteration 730: pre-inner-loop train accuracy: 0.54400, post-inner-loop test accuracy: 0.77600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.61200, meta-validation post-inner-loop test accuracy: 0.75200\n",
            "Iteration 740: pre-inner-loop train accuracy: 0.64000, post-inner-loop test accuracy: 0.72000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.48800, meta-validation post-inner-loop test accuracy: 0.72800\n",
            "Iteration 750: pre-inner-loop train accuracy: 0.40000, post-inner-loop test accuracy: 0.77600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52400, meta-validation post-inner-loop test accuracy: 0.69600\n",
            "Iteration 760: pre-inner-loop train accuracy: 0.40800, post-inner-loop test accuracy: 0.71200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.40000, meta-validation post-inner-loop test accuracy: 0.80800\n",
            "Iteration 770: pre-inner-loop train accuracy: 0.47200, post-inner-loop test accuracy: 0.75200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.58800, meta-validation post-inner-loop test accuracy: 0.88000\n",
            "Iteration 780: pre-inner-loop train accuracy: 0.50400, post-inner-loop test accuracy: 0.87200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.57200, meta-validation post-inner-loop test accuracy: 0.77600\n",
            "Iteration 790: pre-inner-loop train accuracy: 0.60000, post-inner-loop test accuracy: 0.78400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.46400, meta-validation post-inner-loop test accuracy: 0.72800\n",
            "Iteration 800: pre-inner-loop train accuracy: 0.55600, post-inner-loop test accuracy: 0.60000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.48400, meta-validation post-inner-loop test accuracy: 0.67200\n",
            "Saving to  C:/Users/tousi.KCRND/Downloads/MAML/weights/800_model.h5\n",
            "Iteration 810: pre-inner-loop train accuracy: 0.52400, post-inner-loop test accuracy: 0.68000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.54800, meta-validation post-inner-loop test accuracy: 0.74400\n",
            "Iteration 820: pre-inner-loop train accuracy: 0.52000, post-inner-loop test accuracy: 0.65600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.63200, meta-validation post-inner-loop test accuracy: 0.65600\n",
            "Iteration 830: pre-inner-loop train accuracy: 0.54400, post-inner-loop test accuracy: 0.71200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.45600, meta-validation post-inner-loop test accuracy: 0.62400\n",
            "Iteration 840: pre-inner-loop train accuracy: 0.51200, post-inner-loop test accuracy: 0.65600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.48800, meta-validation post-inner-loop test accuracy: 0.70400\n",
            "Iteration 850: pre-inner-loop train accuracy: 0.60800, post-inner-loop test accuracy: 0.70400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.34400, meta-validation post-inner-loop test accuracy: 0.73600\n",
            "Iteration 860: pre-inner-loop train accuracy: 0.48800, post-inner-loop test accuracy: 0.72800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.56400, meta-validation post-inner-loop test accuracy: 0.66400\n",
            "Iteration 870: pre-inner-loop train accuracy: 0.41200, post-inner-loop test accuracy: 0.76000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.50400, meta-validation post-inner-loop test accuracy: 0.62400\n",
            "Iteration 880: pre-inner-loop train accuracy: 0.47200, post-inner-loop test accuracy: 0.70400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.54000, meta-validation post-inner-loop test accuracy: 0.67200\n",
            "Iteration 890: pre-inner-loop train accuracy: 0.49200, post-inner-loop test accuracy: 0.66400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.49600, meta-validation post-inner-loop test accuracy: 0.68800\n",
            "Iteration 900: pre-inner-loop train accuracy: 0.44400, post-inner-loop test accuracy: 0.61600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.53600, meta-validation post-inner-loop test accuracy: 0.62400\n",
            "Saving to  C:/Users/tousi.KCRND/Downloads/MAML/weights/900_model.h5\n",
            "Iteration 910: pre-inner-loop train accuracy: 0.42800, post-inner-loop test accuracy: 0.84800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.45600, meta-validation post-inner-loop test accuracy: 0.68000\n",
            "Iteration 920: pre-inner-loop train accuracy: 0.56800, post-inner-loop test accuracy: 0.64000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.48800, meta-validation post-inner-loop test accuracy: 0.71200\n",
            "Iteration 930: pre-inner-loop train accuracy: 0.59600, post-inner-loop test accuracy: 0.77600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.53600, meta-validation post-inner-loop test accuracy: 0.68000\n",
            "Iteration 940: pre-inner-loop train accuracy: 0.48000, post-inner-loop test accuracy: 0.65600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.37600, meta-validation post-inner-loop test accuracy: 0.83200\n",
            "Iteration 950: pre-inner-loop train accuracy: 0.43200, post-inner-loop test accuracy: 0.71200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.58400, meta-validation post-inner-loop test accuracy: 0.64000\n",
            "Iteration 960: pre-inner-loop train accuracy: 0.44800, post-inner-loop test accuracy: 0.72000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.47200, meta-validation post-inner-loop test accuracy: 0.73600\n",
            "Iteration 970: pre-inner-loop train accuracy: 0.41600, post-inner-loop test accuracy: 0.72800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.49600, meta-validation post-inner-loop test accuracy: 0.75200\n",
            "Iteration 980: pre-inner-loop train accuracy: 0.53200, post-inner-loop test accuracy: 0.79200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.53200, meta-validation post-inner-loop test accuracy: 0.72000\n",
            "Iteration 990: pre-inner-loop train accuracy: 0.63600, post-inner-loop test accuracy: 0.68800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52000, meta-validation post-inner-loop test accuracy: 0.76800\n"
          ]
        }
      ],
      "source": [
        "run_maml(n_way=2, k_shot=5, inner_update_lr=0.1, num_inner_updates=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxSeXg-AMmRY",
        "outputId": "ed3c3ac8-7333-4e52-c9d6-eec281e9b4d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean meta-test accuracy/loss, stddev, and confidence intervals\n",
            "(0.7353334, 0.29294747, 0.023440679640714147)\n"
          ]
        }
      ],
      "source": [
        "# test the model\n",
        "run_maml(n_way=2, k_shot=5, inner_update_lr=0.01, num_inner_updates=1, meta_train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 10: pre-inner-loop train accuracy: 0.46100, post-inner-loop test accuracy: 0.74000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.49200, meta-validation post-inner-loop test accuracy: 0.76800\n",
            "Iteration 20: pre-inner-loop train accuracy: 0.57600, post-inner-loop test accuracy: 0.81200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.45400, meta-validation post-inner-loop test accuracy: 0.70800\n",
            "Iteration 30: pre-inner-loop train accuracy: 0.51000, post-inner-loop test accuracy: 0.70400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.47200, meta-validation post-inner-loop test accuracy: 0.76000\n",
            "Iteration 40: pre-inner-loop train accuracy: 0.54200, post-inner-loop test accuracy: 0.69600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52200, meta-validation post-inner-loop test accuracy: 0.77200\n",
            "Iteration 50: pre-inner-loop train accuracy: 0.51000, post-inner-loop test accuracy: 0.62400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52000, meta-validation post-inner-loop test accuracy: 0.78800\n",
            "Iteration 60: pre-inner-loop train accuracy: 0.43800, post-inner-loop test accuracy: 0.80000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.44400, meta-validation post-inner-loop test accuracy: 0.76000\n",
            "Iteration 70: pre-inner-loop train accuracy: 0.49400, post-inner-loop test accuracy: 0.73200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.47800, meta-validation post-inner-loop test accuracy: 0.68000\n",
            "Iteration 80: pre-inner-loop train accuracy: 0.57200, post-inner-loop test accuracy: 0.76400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.58200, meta-validation post-inner-loop test accuracy: 0.73200\n",
            "Iteration 90: pre-inner-loop train accuracy: 0.55600, post-inner-loop test accuracy: 0.75200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.46800, meta-validation post-inner-loop test accuracy: 0.76400\n",
            "Iteration 100: pre-inner-loop train accuracy: 0.39400, post-inner-loop test accuracy: 0.74000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.51800, meta-validation post-inner-loop test accuracy: 0.68400\n",
            "Saving to  C:/Users/tousi.KCRND/Downloads/MAML/weights/100_model_.h5\n",
            "Iteration 110: pre-inner-loop train accuracy: 0.40400, post-inner-loop test accuracy: 0.69200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.47800, meta-validation post-inner-loop test accuracy: 0.71600\n",
            "Iteration 120: pre-inner-loop train accuracy: 0.48000, post-inner-loop test accuracy: 0.73600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.55400, meta-validation post-inner-loop test accuracy: 0.69200\n",
            "Iteration 130: pre-inner-loop train accuracy: 0.33200, post-inner-loop test accuracy: 0.79200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.53200, meta-validation post-inner-loop test accuracy: 0.71200\n",
            "Iteration 140: pre-inner-loop train accuracy: 0.43800, post-inner-loop test accuracy: 0.67600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.51000, meta-validation post-inner-loop test accuracy: 0.78800\n",
            "Iteration 150: pre-inner-loop train accuracy: 0.48800, post-inner-loop test accuracy: 0.72000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.31200, meta-validation post-inner-loop test accuracy: 0.80800\n",
            "Iteration 160: pre-inner-loop train accuracy: 0.54200, post-inner-loop test accuracy: 0.65200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.64200, meta-validation post-inner-loop test accuracy: 0.78000\n",
            "Iteration 170: pre-inner-loop train accuracy: 0.49800, post-inner-loop test accuracy: 0.78800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.49200, meta-validation post-inner-loop test accuracy: 0.71600\n",
            "Iteration 180: pre-inner-loop train accuracy: 0.59000, post-inner-loop test accuracy: 0.83200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.54000, meta-validation post-inner-loop test accuracy: 0.79200\n",
            "Iteration 190: pre-inner-loop train accuracy: 0.39600, post-inner-loop test accuracy: 0.75200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.35000, meta-validation post-inner-loop test accuracy: 0.77600\n",
            "Iteration 200: pre-inner-loop train accuracy: 0.47600, post-inner-loop test accuracy: 0.83200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.59600, meta-validation post-inner-loop test accuracy: 0.83200\n",
            "Saving to  C:/Users/tousi.KCRND/Downloads/MAML/weights/200_model_.h5\n",
            "Iteration 210: pre-inner-loop train accuracy: 0.48800, post-inner-loop test accuracy: 0.67200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.54200, meta-validation post-inner-loop test accuracy: 0.84000\n",
            "Iteration 220: pre-inner-loop train accuracy: 0.50600, post-inner-loop test accuracy: 0.80800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52800, meta-validation post-inner-loop test accuracy: 0.74400\n",
            "Iteration 230: pre-inner-loop train accuracy: 0.56800, post-inner-loop test accuracy: 0.81600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.40200, meta-validation post-inner-loop test accuracy: 0.75600\n",
            "Iteration 240: pre-inner-loop train accuracy: 0.51800, post-inner-loop test accuracy: 0.72000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.47200, meta-validation post-inner-loop test accuracy: 0.75200\n",
            "Iteration 250: pre-inner-loop train accuracy: 0.46600, post-inner-loop test accuracy: 0.73200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52200, meta-validation post-inner-loop test accuracy: 0.72000\n",
            "Iteration 260: pre-inner-loop train accuracy: 0.44800, post-inner-loop test accuracy: 0.74400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.51200, meta-validation post-inner-loop test accuracy: 0.69600\n",
            "Iteration 270: pre-inner-loop train accuracy: 0.50800, post-inner-loop test accuracy: 0.82400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.48000, meta-validation post-inner-loop test accuracy: 0.72800\n",
            "Iteration 280: pre-inner-loop train accuracy: 0.55600, post-inner-loop test accuracy: 0.78000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.53800, meta-validation post-inner-loop test accuracy: 0.69600\n",
            "Iteration 290: pre-inner-loop train accuracy: 0.45400, post-inner-loop test accuracy: 0.65200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.43600, meta-validation post-inner-loop test accuracy: 0.76000\n",
            "Iteration 300: pre-inner-loop train accuracy: 0.43800, post-inner-loop test accuracy: 0.78400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.50600, meta-validation post-inner-loop test accuracy: 0.78000\n",
            "Saving to  C:/Users/tousi.KCRND/Downloads/MAML/weights/300_model_.h5\n",
            "Iteration 310: pre-inner-loop train accuracy: 0.52600, post-inner-loop test accuracy: 0.72000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.51600, meta-validation post-inner-loop test accuracy: 0.80000\n",
            "Iteration 320: pre-inner-loop train accuracy: 0.67600, post-inner-loop test accuracy: 0.78000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.56200, meta-validation post-inner-loop test accuracy: 0.74000\n",
            "Iteration 330: pre-inner-loop train accuracy: 0.46000, post-inner-loop test accuracy: 0.64000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.51200, meta-validation post-inner-loop test accuracy: 0.74800\n",
            "Iteration 340: pre-inner-loop train accuracy: 0.53400, post-inner-loop test accuracy: 0.68400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.43200, meta-validation post-inner-loop test accuracy: 0.74000\n",
            "Iteration 350: pre-inner-loop train accuracy: 0.49400, post-inner-loop test accuracy: 0.70400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.55800, meta-validation post-inner-loop test accuracy: 0.75200\n",
            "Iteration 360: pre-inner-loop train accuracy: 0.53600, post-inner-loop test accuracy: 0.76000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.50600, meta-validation post-inner-loop test accuracy: 0.75200\n",
            "Iteration 370: pre-inner-loop train accuracy: 0.63800, post-inner-loop test accuracy: 0.75200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.55800, meta-validation post-inner-loop test accuracy: 0.75200\n",
            "Iteration 380: pre-inner-loop train accuracy: 0.45600, post-inner-loop test accuracy: 0.79200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.48600, meta-validation post-inner-loop test accuracy: 0.64400\n",
            "Iteration 390: pre-inner-loop train accuracy: 0.51600, post-inner-loop test accuracy: 0.80000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.44000, meta-validation post-inner-loop test accuracy: 0.69600\n",
            "Iteration 400: pre-inner-loop train accuracy: 0.66400, post-inner-loop test accuracy: 0.76400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.55400, meta-validation post-inner-loop test accuracy: 0.68000\n",
            "Saving to  C:/Users/tousi.KCRND/Downloads/MAML/weights/400_model_.h5\n",
            "Iteration 410: pre-inner-loop train accuracy: 0.46800, post-inner-loop test accuracy: 0.79600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.50800, meta-validation post-inner-loop test accuracy: 0.61200\n",
            "Iteration 420: pre-inner-loop train accuracy: 0.42000, post-inner-loop test accuracy: 0.83600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.45400, meta-validation post-inner-loop test accuracy: 0.73600\n",
            "Iteration 430: pre-inner-loop train accuracy: 0.55000, post-inner-loop test accuracy: 0.66800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.55800, meta-validation post-inner-loop test accuracy: 0.72800\n",
            "Iteration 440: pre-inner-loop train accuracy: 0.55800, post-inner-loop test accuracy: 0.74800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52000, meta-validation post-inner-loop test accuracy: 0.78000\n",
            "Iteration 450: pre-inner-loop train accuracy: 0.51400, post-inner-loop test accuracy: 0.70800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.49400, meta-validation post-inner-loop test accuracy: 0.72400\n",
            "Iteration 460: pre-inner-loop train accuracy: 0.47200, post-inner-loop test accuracy: 0.67200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.48200, meta-validation post-inner-loop test accuracy: 0.84000\n",
            "Iteration 470: pre-inner-loop train accuracy: 0.58000, post-inner-loop test accuracy: 0.72000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.62400, meta-validation post-inner-loop test accuracy: 0.68000\n",
            "Iteration 480: pre-inner-loop train accuracy: 0.43000, post-inner-loop test accuracy: 0.76000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.46400, meta-validation post-inner-loop test accuracy: 0.78000\n",
            "Iteration 490: pre-inner-loop train accuracy: 0.58600, post-inner-loop test accuracy: 0.57400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.46400, meta-validation post-inner-loop test accuracy: 0.45600\n"
          ]
        }
      ],
      "source": [
        "run_maml(n_way=2, k_shot=10, inner_update_lr=0.01, num_inner_updates=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean meta-test accuracy/loss, stddev, and confidence intervals\n",
            "(0.74333334, 0.26798114, 0.021442957231667194)\n"
          ]
        }
      ],
      "source": [
        "run_maml(n_way=2, k_shot=10, inner_update_lr=0.4, num_inner_updates=1, meta_train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TR-1zDCsZqBy",
        "outputId": "181bf99a-6b4e-494e-a6a7-34daf87be196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:From c:\\Users\\tousi.KCRND\\AppData\\Local\\miniconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "Iteration 10: pre-inner-loop train accuracy: 0.55000, post-inner-loop test accuracy: 0.75600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.38800, meta-validation post-inner-loop test accuracy: 0.73600\n",
            "Iteration 20: pre-inner-loop train accuracy: 0.50400, post-inner-loop test accuracy: 0.77600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52800, meta-validation post-inner-loop test accuracy: 0.78400\n",
            "Iteration 30: pre-inner-loop train accuracy: 0.41200, post-inner-loop test accuracy: 0.80000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.65200, meta-validation post-inner-loop test accuracy: 0.75200\n",
            "Iteration 40: pre-inner-loop train accuracy: 0.54800, post-inner-loop test accuracy: 0.73600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52800, meta-validation post-inner-loop test accuracy: 0.67200\n",
            "Iteration 50: pre-inner-loop train accuracy: 0.59600, post-inner-loop test accuracy: 0.68800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.56000, meta-validation post-inner-loop test accuracy: 0.84000\n",
            "Iteration 60: pre-inner-loop train accuracy: 0.50000, post-inner-loop test accuracy: 0.74400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.51200, meta-validation post-inner-loop test accuracy: 0.78400\n",
            "Iteration 70: pre-inner-loop train accuracy: 0.50400, post-inner-loop test accuracy: 0.85600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.61200, meta-validation post-inner-loop test accuracy: 0.71200\n",
            "Iteration 80: pre-inner-loop train accuracy: 0.53200, post-inner-loop test accuracy: 0.76000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.47200, meta-validation post-inner-loop test accuracy: 0.73600\n",
            "Iteration 90: pre-inner-loop train accuracy: 0.55600, post-inner-loop test accuracy: 0.67200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.48400, meta-validation post-inner-loop test accuracy: 0.75200\n",
            "Iteration 100: pre-inner-loop train accuracy: 0.68400, post-inner-loop test accuracy: 0.76400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.64000, meta-validation post-inner-loop test accuracy: 0.72000\n",
            "Saving to  C:/Users/tousi.KCRND/Downloads/MAML/weights/100_model.h5\n",
            "Iteration 110: pre-inner-loop train accuracy: 0.58400, post-inner-loop test accuracy: 0.61600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.66000, meta-validation post-inner-loop test accuracy: 0.78400\n",
            "Iteration 120: pre-inner-loop train accuracy: 0.48800, post-inner-loop test accuracy: 0.71200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52400, meta-validation post-inner-loop test accuracy: 0.80800\n",
            "Iteration 130: pre-inner-loop train accuracy: 0.52400, post-inner-loop test accuracy: 0.70800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.47200, meta-validation post-inner-loop test accuracy: 0.77600\n",
            "Iteration 140: pre-inner-loop train accuracy: 0.44000, post-inner-loop test accuracy: 0.80800\n",
            "Meta-validation pre-inner-loop train accuracy: 0.56000, meta-validation post-inner-loop test accuracy: 0.68800\n",
            "Iteration 150: pre-inner-loop train accuracy: 0.48000, post-inner-loop test accuracy: 0.70400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.56000, meta-validation post-inner-loop test accuracy: 0.71200\n",
            "Iteration 160: pre-inner-loop train accuracy: 0.55200, post-inner-loop test accuracy: 0.70400\n",
            "Meta-validation pre-inner-loop train accuracy: 0.41200, meta-validation post-inner-loop test accuracy: 0.69600\n",
            "Iteration 170: pre-inner-loop train accuracy: 0.53600, post-inner-loop test accuracy: 0.67200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.57600, meta-validation post-inner-loop test accuracy: 0.67200\n",
            "Iteration 180: pre-inner-loop train accuracy: 0.50000, post-inner-loop test accuracy: 0.69200\n",
            "Meta-validation pre-inner-loop train accuracy: 0.50800, meta-validation post-inner-loop test accuracy: 0.70000\n",
            "Iteration 190: pre-inner-loop train accuracy: 0.42000, post-inner-loop test accuracy: 0.69600\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52000, meta-validation post-inner-loop test accuracy: 0.76000\n"
          ]
        }
      ],
      "source": [
        "# Run MAML with learnable learning rate\n",
        "run_maml(n_way=2, k_shot=5, inner_update_lr=4.0, num_inner_updates=1, learn_inner_update_lr=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "x4klmf_RZqBy",
        "outputId": "f340895f-234f-4fef-f3c1-bd4646bcbb0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean meta-test accuracy/loss, stddev, and confidence intervals\n",
            "(0.76000005, 0.2842534, 0.05571366417407989)\n"
          ]
        }
      ],
      "source": [
        "run_maml(n_way=2, k_shot=5, inner_update_lr=0.4, num_inner_updates=1, meta_train=False, learn_inner_update_lr=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 10: pre-inner-loop train accuracy: 0.38571, post-inner-loop test accuracy: 0.74857\n",
            "Meta-validation pre-inner-loop train accuracy: 0.41714, meta-validation post-inner-loop test accuracy: 0.77143\n",
            "Iteration 20: pre-inner-loop train accuracy: 0.47714, post-inner-loop test accuracy: 0.68000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.39143, meta-validation post-inner-loop test accuracy: 0.66857\n",
            "Iteration 30: pre-inner-loop train accuracy: 0.45143, post-inner-loop test accuracy: 0.74857\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52286, meta-validation post-inner-loop test accuracy: 0.76571\n",
            "Iteration 40: pre-inner-loop train accuracy: 0.45429, post-inner-loop test accuracy: 0.70286\n",
            "Meta-validation pre-inner-loop train accuracy: 0.52000, meta-validation post-inner-loop test accuracy: 0.78286\n",
            "Iteration 50: pre-inner-loop train accuracy: 0.56571, post-inner-loop test accuracy: 0.73143\n",
            "Meta-validation pre-inner-loop train accuracy: 0.54000, meta-validation post-inner-loop test accuracy: 0.79429\n",
            "Iteration 60: pre-inner-loop train accuracy: 0.47714, post-inner-loop test accuracy: 0.68000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.45714, meta-validation post-inner-loop test accuracy: 0.69714\n",
            "Iteration 70: pre-inner-loop train accuracy: 0.57143, post-inner-loop test accuracy: 0.74857\n",
            "Meta-validation pre-inner-loop train accuracy: 0.42000, meta-validation post-inner-loop test accuracy: 0.69143\n",
            "Iteration 80: pre-inner-loop train accuracy: 0.58857, post-inner-loop test accuracy: 0.74286\n",
            "Meta-validation pre-inner-loop train accuracy: 0.60571, meta-validation post-inner-loop test accuracy: 0.78286\n",
            "Iteration 90: pre-inner-loop train accuracy: 0.64000, post-inner-loop test accuracy: 0.77143\n",
            "Meta-validation pre-inner-loop train accuracy: 0.39714, meta-validation post-inner-loop test accuracy: 0.69714\n",
            "Iteration 100: pre-inner-loop train accuracy: 0.51714, post-inner-loop test accuracy: 0.72571\n",
            "Meta-validation pre-inner-loop train accuracy: 0.58857, meta-validation post-inner-loop test accuracy: 0.68000\n",
            "Saving to  C:/Users/tousi.KCRND/Downloads/MAML/weights/100_model.h5\n",
            "Iteration 110: pre-inner-loop train accuracy: 0.40000, post-inner-loop test accuracy: 0.85143\n",
            "Meta-validation pre-inner-loop train accuracy: 0.34000, meta-validation post-inner-loop test accuracy: 0.78286\n",
            "Iteration 120: pre-inner-loop train accuracy: 0.51429, post-inner-loop test accuracy: 0.70857\n",
            "Meta-validation pre-inner-loop train accuracy: 0.49429, meta-validation post-inner-loop test accuracy: 0.62857\n",
            "Iteration 130: pre-inner-loop train accuracy: 0.46286, post-inner-loop test accuracy: 0.80000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.62571, meta-validation post-inner-loop test accuracy: 0.74286\n",
            "Iteration 140: pre-inner-loop train accuracy: 0.56571, post-inner-loop test accuracy: 0.76000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.48857, meta-validation post-inner-loop test accuracy: 0.66857\n",
            "Iteration 150: pre-inner-loop train accuracy: 0.53143, post-inner-loop test accuracy: 0.75429\n",
            "Meta-validation pre-inner-loop train accuracy: 0.49143, meta-validation post-inner-loop test accuracy: 0.75429\n",
            "Iteration 160: pre-inner-loop train accuracy: 0.43429, post-inner-loop test accuracy: 0.73143\n",
            "Meta-validation pre-inner-loop train accuracy: 0.61429, meta-validation post-inner-loop test accuracy: 0.69714\n",
            "Iteration 170: pre-inner-loop train accuracy: 0.51143, post-inner-loop test accuracy: 0.73714\n",
            "Meta-validation pre-inner-loop train accuracy: 0.39714, meta-validation post-inner-loop test accuracy: 0.72571\n",
            "Iteration 180: pre-inner-loop train accuracy: 0.40857, post-inner-loop test accuracy: 0.74286\n",
            "Meta-validation pre-inner-loop train accuracy: 0.58000, meta-validation post-inner-loop test accuracy: 0.68000\n",
            "Iteration 190: pre-inner-loop train accuracy: 0.49143, post-inner-loop test accuracy: 0.68000\n",
            "Meta-validation pre-inner-loop train accuracy: 0.57429, meta-validation post-inner-loop test accuracy: 0.70857\n"
          ]
        }
      ],
      "source": [
        "run_maml(n_way=2, k_shot=7, inner_update_lr=0.4, num_inner_updates=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean meta-test accuracy/loss, stddev, and confidence intervals\n",
            "(0.77700007, 0.26677895, 0.05228867340087891)\n"
          ]
        }
      ],
      "source": [
        "run_maml(n_way=2, k_shot=10, inner_update_lr=0.4, num_inner_updates=1, meta_train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "def meta_fine_tune(model, data_generator,\n",
        "               n_way=2, meta_train_iterations=200, meta_batch_size=25,\n",
        "               k_shot=5, num_inner_updates=1, meta_lr=0.0001):\n",
        "\n",
        "  SUMMARY_INTERVAL = 10\n",
        "  SAVE_INTERVAL = 100\n",
        "  PRINT_INTERVAL = SUMMARY_INTERVAL\n",
        "  TEST_PRINT_INTERVAL = SUMMARY_INTERVAL\n",
        "  LOG_CSV_INTERVAL = SUMMARY_INTERVAL\n",
        "\n",
        "  path = 'C:/Users/tousi.KCRND/Downloads/MAML/finetune/'\n",
        "\n",
        "  pre_accuracies, post_accuracies = [], []\n",
        "\n",
        "  num_classes = 2\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=meta_lr)\n",
        "\n",
        "  task_train_acc_pre_optim, task_train_acc_post_optim, task_test_acc_pre_optim, task_test_acc_post_optim = 0., 0., 0., 0.\n",
        "\n",
        "  for itr in range(meta_train_iterations):\n",
        "\n",
        "    input_, label_ = data_generator.sample_batch(batch_type='meta_fine_tune', batch_size=meta_batch_size, shuffle=True)\n",
        "    #print('input shape:',input_.shape)\n",
        "\n",
        "    input_tr = np.reshape(input_[:, :n_way*k_shot, :], newshape=(-1, np.prod(data_generator.dim_input)))\n",
        "    input_ts = np.reshape(input_[:, n_way*k_shot:, :], newshape=(-1, np.prod(data_generator.dim_input)))\n",
        "    label_tr = np.reshape(label_[:, :n_way*k_shot, :], newshape=(-1, data_generator.dim_output))\n",
        "    label_ts = np.reshape(label_[:, n_way*k_shot:, :], newshape=(-1, data_generator.dim_output))\n",
        "\n",
        "    input_tr = np.reshape(input_tr, newshape=(-1, 1000, 1, 1))  \n",
        "    input_ts = np.reshape(input_ts, newshape=(-1, 1000, 1, 1))\n",
        "\n",
        "\n",
        "    inp = (input_tr, input_ts, label_tr, label_ts)\n",
        "\n",
        "    result = outer_train_step(inp, model, optimizer, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n",
        "\n",
        "    if itr % SUMMARY_INTERVAL == 0:\n",
        "      pre_accuracies.append(result[-2])\n",
        "      post_accuracies.append(result[-1][-1])\n",
        "\n",
        "    if (itr!=0) and itr % PRINT_INTERVAL == 0:\n",
        "      task_train_acc_pre_optim = np.mean(pre_accuracies)\n",
        "      task_train_acc_post_optim = np.mean(post_accuracies)\n",
        "      print_str = 'Iteration %d: pre-inner-loop train accuracy: %.5f, post-inner-loop test accuracy: %.5f' % (itr, np.mean(pre_accuracies), np.mean(post_accuracies))\n",
        "      print(print_str)\n",
        "      pre_accuracies, post_accuracies = [], []\n",
        "\n",
        "\n",
        "    if (itr != 0) and itr % SAVE_INTERVAL == 0:\n",
        "        model_file = os.path.join(path, f'{itr}_model_.h5')\n",
        "        print(\"Saving to \", model_file)\n",
        "        model.save_weights(model_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_finetune(n_way, k_shot, meta_batch_size=25, meta_lr=0.0001,\n",
        "             inner_update_lr=0.4, num_inner_updates=1,\n",
        "             learn_inner_update_lr=False,\n",
        "             resume=False, resume_itr=0,\n",
        "             meta_train=True,\n",
        "             meta_train_iterations=200, meta_train_k_shot=-1,\n",
        "             meta_train_inner_update_lr=-1):\n",
        "\n",
        "  # call data_generator and get data with k_shot*2 samples per class\n",
        "\n",
        "  path = 'C:/Users/tousi.KCRND/Downloads/MAML/finetune/'\n",
        "\n",
        "  data_generator = DataGenerator(X_train, y_train, n_way, k_shot*2,\n",
        "                               X_val, y_val, X_train_meta, y_train_meta, X_test_meta,\n",
        "                               y_test_meta, n_way, k_shot*2)\n",
        "\n",
        "\n",
        "  # set up MAML model\n",
        "  dim_output = data_generator.dim_output\n",
        "  dim_input = data_generator.dim_input\n",
        "  #print('1')\n",
        "  model = MAML(dim_input,\n",
        "              dim_output,\n",
        "              num_inner_updates=num_inner_updates,\n",
        "              inner_update_lr=inner_update_lr,\n",
        "              k_shot=k_shot,\n",
        "              learn_inner_update_lr=learn_inner_update_lr)\n",
        "  #print('2')\n",
        "  if meta_train_k_shot == -1:\n",
        "    meta_train_k_shot = k_shot\n",
        "  if meta_train_inner_update_lr == -1:\n",
        "    meta_train_inner_update_lr = inner_update_lr\n",
        "\n",
        "\n",
        "  if meta_train:\n",
        "    meta_fine_tune(model, data_generator,\n",
        "                  n_way, meta_train_iterations, meta_batch_size, k_shot,\n",
        "                  num_inner_updates, meta_lr)\n",
        "  else:\n",
        "    meta_batch_size = 1\n",
        "    # latest_checkpoint = tf.train.latest_checkpoint(path)\n",
        "    # print(\"Restoring model weights from \", latest_checkpoint)\n",
        "    # model.load_weights(latest_checkpoint)\n",
        "    meta_test_fn(model, data_generator, n_way, meta_batch_size, k_shot, num_inner_updates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 10: pre-inner-loop train accuracy: 0.52200, post-inner-loop test accuracy: 0.73600\n",
            "Iteration 20: pre-inner-loop train accuracy: 0.45200, post-inner-loop test accuracy: 0.75200\n",
            "Iteration 30: pre-inner-loop train accuracy: 0.54400, post-inner-loop test accuracy: 0.75200\n",
            "Iteration 40: pre-inner-loop train accuracy: 0.45200, post-inner-loop test accuracy: 0.62400\n",
            "Iteration 50: pre-inner-loop train accuracy: 0.43200, post-inner-loop test accuracy: 0.76800\n",
            "Iteration 60: pre-inner-loop train accuracy: 0.54000, post-inner-loop test accuracy: 0.84000\n",
            "Iteration 70: pre-inner-loop train accuracy: 0.47600, post-inner-loop test accuracy: 0.76000\n",
            "Iteration 80: pre-inner-loop train accuracy: 0.54000, post-inner-loop test accuracy: 0.65600\n",
            "Iteration 90: pre-inner-loop train accuracy: 0.51200, post-inner-loop test accuracy: 0.73600\n",
            "Iteration 100: pre-inner-loop train accuracy: 0.55200, post-inner-loop test accuracy: 0.69600\n",
            "Saving to  C:/Users/tousi.KCRND/Downloads/MAML/finetune/100_model_.h5\n",
            "Iteration 110: pre-inner-loop train accuracy: 0.55600, post-inner-loop test accuracy: 0.77600\n",
            "Iteration 120: pre-inner-loop train accuracy: 0.58800, post-inner-loop test accuracy: 0.72800\n",
            "Iteration 130: pre-inner-loop train accuracy: 0.48000, post-inner-loop test accuracy: 0.72000\n",
            "Iteration 140: pre-inner-loop train accuracy: 0.43200, post-inner-loop test accuracy: 0.69600\n",
            "Iteration 150: pre-inner-loop train accuracy: 0.43200, post-inner-loop test accuracy: 0.80000\n",
            "Iteration 160: pre-inner-loop train accuracy: 0.53600, post-inner-loop test accuracy: 0.84000\n",
            "Iteration 170: pre-inner-loop train accuracy: 0.62000, post-inner-loop test accuracy: 0.76000\n",
            "Iteration 180: pre-inner-loop train accuracy: 0.42800, post-inner-loop test accuracy: 0.72800\n",
            "Iteration 190: pre-inner-loop train accuracy: 0.41200, post-inner-loop test accuracy: 0.64800\n"
          ]
        }
      ],
      "source": [
        "run_finetune(n_way=2, k_shot=5, inner_update_lr=0.4, num_inner_updates=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean meta-test accuracy/loss, stddev, and confidence intervals\n",
            "(0.76000005, 0.2842534, 0.05571366417407989)\n"
          ]
        }
      ],
      "source": [
        "run_finetune(n_way=2, k_shot=5, inner_update_lr=0.4, num_inner_updates=1, meta_train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean meta-test accuracy/loss, stddev, and confidence intervals\n",
            "(0.77700007, 0.26677895, 0.05228867340087891)\n"
          ]
        }
      ],
      "source": [
        "run_finetune(n_way=2, k_shot=10, inner_update_lr=0.4, num_inner_updates=1, meta_train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean meta-test accuracy/loss, stddev, and confidence intervals\n",
            "(0.7513333, 0.25679302, 0.05033143234252929)\n"
          ]
        }
      ],
      "source": [
        "run_finetune(n_way=2, k_shot=15, inner_update_lr=0.4, num_inner_updates=1, meta_train=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
